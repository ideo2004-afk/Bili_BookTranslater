# Bili (AI 雙語電子書製作工具)

這是一個利用 AI (ChatGPT, Gemini, Claude, Ollama 等) 來協助翻譯 EPUB/TXT/SRT 電子書與字幕的工具。專為製作高品質的雙語閱讀材料而設計。

---

## ✨ 主要功能

*   **圖形化介面 (GUI)**：提供直覺的操作介面，支援拖放檔案、進度條顯示與即時日誌。
*   **多模型支援**：
    *   **雲端模型**：OpenAI (GPT-4o, GPT-5), Google (Gemini 1.5/2.5 Pro/Flash), Claude 3.5 Sonnet 等。
    *   **本地模型**：完美支援 Ollama (Llama 3, Qwen 2.5 等)，隱私安全且免費。
*   **上下文感知 (Context-Aware)**：
    *   讓 AI 記住前面的劇情發展，確保翻譯連貫性（推薦用於 Gemini/GPT-4 等大模型）。
*   **智慧術語表 (Glossary)**：
    *   自動提取並維護人名、地名等專有名詞，確保整本書的翻譯一致性。
*   **中斷續傳 (Resume)**：
    *   翻譯到一半出錯或想暫停？隨時可以從中斷點繼續，不會浪費已翻譯的進度。
*   **並行處理**：支援多執行緒並行翻譯，大幅提升速度。

---

## 🚀 快速開始 (一鍵安裝與執行)

我們提供了自動化腳本，讓您無需懂程式碼也能輕鬆使用。

### macOS / Linux 使用者

1.  **安裝環境** (只需執行一次)：
    *   雙擊 `install.command` (或在終端機執行 `./install.command`)。
    *   腳本會自動建立虛擬環境並安裝所有必要套件。
3.  **啟動程式**：
    *   雙擊 `run_gui.command` 即可開啟介面 (Bili 原文書翻譯)。

### Windows 使用者

1.  **安裝環境** (只需執行一次)：
    *   雙擊 `install.bat`。
2.  **啟動程式**：
    *   雙擊 `run_gui.bat` 即可開啟介面。

---

## 📖 使用教學 (GUI 介面)

1.  **設定 API Key**：
    *   開啟程式後，點擊左側「設定」圖示。
    *   選擇您要使用的模型 (如 `gemini`, `chatgptapi`, `ollama`)。
    *   填入對應的 API Key (Ollama 無需 Key)。
2.  **加入書籍**：
    *   將 `.epub`, `.txt`, 或 `.srt` 檔案直接拖入程式視窗。
3.  **開始翻譯**：
    *   點擊列表中的書籍，按下「開始翻譯」。
    *   您可以隨時暫停或刪除任務。

### 💡 最佳實踐建議

> [!TIP]
> **關於「上下文感知」(--use_context) 的設定建議：**
>
> *   **✅ 雲端大模型 (Gemini 1.5/2.5 Pro, GPT-4o)**：強烈建議 **開啟**。這些模型擁有巨大的 Context Window，能記住整本書的劇情，開啟後翻譯品質與連貫性會大幅提升。
> *   **❌ 本地小模型 (Ollama 8B, Llama 3 等)**：建議 **關閉**。小模型的記憶力有限，輸入過多歷史紀錄會導致運算變慢（顯卡跑不動）且容易產生幻覺或注意力渙散。

---

## ⚙️ 進階設定說明

在設定頁面中，您可以調整以下參數：

*   **累積 Token (Accumulated Num)**：
    *   控制每次發送給 AI 的文字量。
    *   建議值：`1500` - `2500` (Gemini/GPT-4)，`600` - `1000` (本地模型)。
*   **請求間隔 (Interval)**：
    *   設定每次 API 請求的間隔秒數，避免觸發 Rate Limit (429 錯誤)。
    *   Gemini 免費版建議設為 `2.0` 秒以上。
*   **Prompt 模板**：
    *   您可以自定義翻譯的 Prompt，或是選擇內建的模板 (如 `prompt_cyber.json` 賽博龐克風格)。

---

## 🛠️ 常見問題 (FAQ)

**Q: 翻譯到一半程式當掉怎麼辦？**
A: 直接重新啟動程式，再次執行該任務。程式會詢問是否「從中斷點續傳 (Resume)」，選擇「是」即可接著翻，完全不用重頭來。

**Q: 為什麼本地 Ollama 翻譯很慢？**
A: 請檢查是否開啟了 `--use_context`。對於 8B 左右的小模型，過長的 Context 會導致顯著的效能下降。請關閉此選項並將 `Accumulated Num` 調小。

**Q: 如何備份或搬移程式到新電腦？**
A: 將整個專案資料夾複製過去即可。**不需要**複製 `venv` 資料夾。在新電腦上重新執行 `install.command` (macOS) 或 `install.bat` (Windows) 即可完成環境建置。

---

## 📝 支援的模型列表

### 💰 模型費用參考 (每百萬 Token)

| 模型 | 輸入 (Input) | 輸出 (Output) | 特色與建議 |
| :--- | :--- | :--- | :--- |
| **Gemini 2.0 Flash** | **$0.10** | **$0.40** | **極致性價比**。速度極快，適合大量翻譯或預算有限時使用。 |
| **Gemini 2.5 Pro** | $1.25 | $10.00 | **推理模型**。包含大量隱形 Thinking Token (約佔 80%)，精準但昂貴。 |
| **Gemini 2.5 Flash** | $0.30 | $2.50 | **高速推理**。比 Pro 便宜，但仍含 Thinking Token。 |
| **GPT-5.1** | $1.25 | $10.00 | **最新旗艦**。比 4o 更強的人性化與客製化能力。 |
| **GPT-4o** | $5.00 | $15.00 | **業界標準**。綜合能力強，反應直覺快速，價格適中。 |
| **Local (Ollama)** | **$0** | **$0** | **完全免費**。隱私最高，依賴顯卡效能 (推薦 llama3, qwen2.5)。 |

> 價格可能隨官方政策變動，請以 OpenAI / Google 官網為準。

*   **其他支援**: `gemini-2.5-flash-lite`, `gpt-5-mini`

---

## ⚠️ 免責聲明

本工具僅供個人學習與研究使用。請勿用於翻譯有版權爭議的書籍並進行散布。使用者需自行承擔使用本工具所產生的一切法律責任。
